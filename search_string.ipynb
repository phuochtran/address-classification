{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the data"
      ],
      "metadata": {
        "id": "gTWZ3aOOZfvv"
      },
      "id": "gTWZ3aOOZfvv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e7972f-57a7-43a5-9750-ca3192a5e9fd",
      "metadata": {
        "id": "b4e7972f-57a7-43a5-9750-ca3192a5e9fd"
      },
      "outputs": [],
      "source": [
        "provinces = [\"Long An\", \"Hà Nội\", \"Hồ Chí Minh\", \"Bắc Ninh\"]\n",
        "districts = [\"Cần Giuộc\", \"Quận 1\"]\n",
        "wards = [\"Thuận Thành\", \"An Phú\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalized functions\n",
        "https://github.com/phuochtran/address-classification/blob/main/gpt.md"
      ],
      "metadata": {
        "id": "2mxESKi6Z2nA"
      },
      "id": "2mxESKi6Z2nA"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "import time\n",
        "\n",
        "def strip_accents(s: str) -> str:\n",
        "    s = unicodedata.normalize('NFD', s)\n",
        "    s = ''.join(ch for ch in s if unicodedata.category(ch) != 'Mn')\n",
        "    return unicodedata.normalize('NFC', s)\n",
        "\n",
        "def normalize(s: str) -> str:\n",
        "    s = s.lower()\n",
        "    # replace common punctuation with spaces\n",
        "    s = re.sub(r'[\\.,;/\\\\\\(\\)\\[\\]\\-_:]', ' ', s)\n",
        "    s = s.replace('\\'', ' ')\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    s = strip_accents(s)\n",
        "    # remove any non-alphanumeric (keep spaces)\n",
        "    s = re.sub(r'[^a-z0-9\\s]', '', s)\n",
        "    #remove prefix: h., x., t.\n",
        "    s = re.sub(r'^(h\\.|x\\.|t\\.)\\s*', '', s)\n",
        "    s = re.sub(r'\\b(h|x|t)\\b', ' ', s)\n",
        "    #remove duplicate char, i.e, aabb => ab\n",
        "    s = re.sub(r'(.)\\1+', r'\\1', s)\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    return s"
      ],
      "metadata": {
        "id": "TWwsryQUza9-"
      },
      "id": "TWwsryQUza9-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Trie for provinces, districts and wards"
      ],
      "metadata": {
        "id": "yaSvlGu2aH05"
      },
      "id": "yaSvlGu2aH05"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10f999f1-53fb-413d-83ef-f488ee81aa5f",
      "metadata": {
        "id": "10f999f1-53fb-413d-83ef-f488ee81aa5f"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import sys\n",
        "\n",
        "class TrieNode:\n",
        "    def __init__(self):\n",
        "      #Since the node is normalized, we should store the whole word instead is_terminal\n",
        "      self.word = None\n",
        "      self.children = {}\n",
        "\n",
        "    def insert(self,word):\n",
        "        node = self\n",
        "        for letter in word:\n",
        "            letter = strip_accents(letter).lower()\n",
        "            if letter not in node.children:\n",
        "                node.children[letter] = TrieNode()\n",
        "            node = node.children[letter]\n",
        "        node.word = word\n",
        "\n",
        "# read dictionary file into a trie\n",
        "provinceTrie = TrieNode()\n",
        "for word in provinces:\n",
        "    provinceTrie.insert(word)\n",
        "districtTrie = TrieNode()\n",
        "for word in districts:\n",
        "    districtTrie.insert(word)\n",
        "wardTrie = TrieNode()\n",
        "for word in wards:\n",
        "    wardTrie.insert(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main function**\n",
        "*Description*: Searching for a word using Trie and levanstein distance approach(i.e. edit distance).\n",
        "\n",
        "*    While traversing the Trie, we also calculate the levanstein distance's row for the character (i.e. edit cost).\n",
        "*    Once we meet the node which contain the word (`is_terminal = true/word != None`), we start compare the number of edit to the edit threshold:\n",
        "1.   If it satisfied, we store that word along with the cost.\n",
        "2.   If the word still have more childs and edit threshold is not break, we continue searching recursively.  \n",
        "*   Finally, return the best word."
      ],
      "metadata": {
        "id": "lgw-r9wzabSZ"
      },
      "id": "lgw-r9wzabSZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c0909cd-a34c-420a-afc3-effc6cf42f81",
      "metadata": {
        "id": "2c0909cd-a34c-420a-afc3-effc6cf42f81"
      },
      "outputs": [],
      "source": [
        "class SearchResult:\n",
        "    def __init__(self):\n",
        "        self.word = \"\"\n",
        "        self.cost = float('inf')\n",
        "\n",
        "def findBestResult(word:str, trie:TrieNode, editThreshold:int, debug = False) -> SearchResult:\n",
        "    #calculate basecase for levastein distance\n",
        "    currentRow = range(len(word) + 1)\n",
        "    result = SearchResult();\n",
        "    # recursively search each branch of the trie\n",
        "    for letter in trie.children:\n",
        "        findAllPossibleResults(trie.children[letter],\n",
        "                        letter,\n",
        "                        word,\n",
        "                        currentRow,\n",
        "                        result,\n",
        "                        editThreshold,\n",
        "                        debug)\n",
        "    return result\n",
        "\n",
        "def findAllPossibleResults(node: TrieNode,\n",
        "                    letter:str,\n",
        "                    word:str,\n",
        "                    previousRow:range,\n",
        "                    result: SearchResult,\n",
        "                    editThreshold: int,\n",
        "                    debug = False):\n",
        "    columns = len(word) + 1\n",
        "    currentRow = [previousRow[0] + 1]\n",
        "\n",
        "    #here we calculate each levanstein distance's row for the character\n",
        "    for column in range(1, columns):\n",
        "        insertCost = currentRow[column - 1] + 1\n",
        "        deleteCost = previousRow[column] + 1\n",
        "        if word[column - 1].lower() != letter:\n",
        "            replaceCost = previousRow[column - 1] + 1\n",
        "        else:\n",
        "            replaceCost = previousRow[column - 1]\n",
        "        currentRow.append(min(insertCost, deleteCost, replaceCost))\n",
        "\n",
        "    #If the node is a complete word, edit cost is < limit and the cost is smallest, we store it\n",
        "    if currentRow[-1] <= editThreshold and node.word != None:\n",
        "        if debug:\n",
        "            print(f\"({node.word}-{currentRow[-1]})\")\n",
        "        if currentRow[-1] < result.cost:\n",
        "            result.word = node.word\n",
        "            result.cost = currentRow[-1]\n",
        "    #After that, we continue searching for more possible results on the child if we are still able to (<= editThreshold)\n",
        "    if min(currentRow) <= editThreshold:\n",
        "        for letter in node.children:\n",
        "            findAllPossibleResults(node.children[letter],\n",
        "                            letter,\n",
        "                            word,\n",
        "                            currentRow,\n",
        "                            result,\n",
        "                            editThreshold, debug)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution and evaluate the result"
      ],
      "metadata": {
        "id": "KUy1Cr6EdYGy"
      },
      "id": "KUy1Cr6EdYGy"
    },
    {
      "cell_type": "code",
      "source": [
        "class Result:\n",
        "    def __init__(self):\n",
        "        self.province = SearchResult()\n",
        "        self.district = SearchResult()\n",
        "        self.ward = SearchResult()\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Province: {self.province.word} | District: {self.district.word} | Ward: {self.ward.word}\"\n",
        "\n",
        "def tokenizeString(text, min_words=1, max_words=4):\n",
        "    words = text.split()\n",
        "    tokens = []\n",
        "\n",
        "    for n in range(min_words, max_words + 1):\n",
        "        for i in range(len(words) - n + 1):\n",
        "            token = ' '.join(words[i:i+n])\n",
        "            tokens.append(token)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "def findBestMatchAddress(text: str):\n",
        "    # build candidate substrings (window up to 4 tokens; addresses usually short).\n",
        "    #References: https://github.com/phuochtran/address-classification/blob/main/gpt.md\n",
        "    candidates = tokenizeString(text)\n",
        "    finalResult = Result()\n",
        "    for candidate in candidates:\n",
        "        provinceResult = findBestResult(candidate, provinceTrie, 3)\n",
        "        districtResult = findBestResult(candidate, districtTrie, 3)\n",
        "        wardResult = findBestResult(candidate, wardTrie, 3)\n",
        "        #Compare and get best result for each level\n",
        "        if finalResult.province.cost > provinceResult.cost:\n",
        "            finalResult.province = provinceResult\n",
        "        if finalResult.district.cost > districtResult.cost:\n",
        "            finalResult.district = districtResult\n",
        "        if finalResult.ward.cost > wardResult.cost:\n",
        "            finalResult.ward = wardResult\n",
        "\n",
        "    return finalResult"
      ],
      "metadata": {
        "id": "PQvFHk8rN5gf"
      },
      "id": "PQvFHk8rN5gf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8fef874-dcd8-42fd-bcaf-e53758b2e987",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8fef874-dcd8-42fd-bcaf-e53758b2e987",
        "outputId": "d68d6df6-4325-4565-c4cb-99927d8d0920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X. Thuận Thành, H. Cần Giuộc, T. Long Aaaaan => thuan thanh can giuoc long aaaaan\n",
            "Evaluate Province: Long An | District: Cần Giuộc | Ward: Thuận Thành within 0.004898548126220703 s\n",
            "Thuận Thanh, HCần Giuộc, Tlong An => thuan thanh hcan giuoc tlong an\n",
            "Evaluate Province: Long An | District: Cần Giuộc | Ward: Thuận Thành within 0.005359172821044922 s\n",
            "Thuận Thành, H Cần Giuộc T. Long An => thuan thanh can giuoc long an\n",
            "Evaluate Province: Long An | District: Cần Giuộc | Ward: Thuận Thành within 0.005868196487426758 s\n",
            "X ThuanThanh H. Can Giuoc, Long An => thuanthanh can giuoc long an\n",
            "Evaluate Province: Long An | District: Cần Giuộc | Ward: Thuận Thành within 0.0034797191619873047 s\n",
            "ThuanThanh H Can Giuoc Long An => thuanthanh can giuoc long an\n",
            "Evaluate Province: Long An | District: Cần Giuộc | Ward: Thuận Thành within 0.004303455352783203 s\n",
            "X ThuanThanh H. Can Giuoc, LongAn => thuanthanh can giuoc longan\n",
            "Evaluate Province: Long An | District: Cần Giuộc | Ward: Thuận Thành within 0.004914760589599609 s\n",
            "H. Can   Giuoc, Long An => can giuoc long an\n",
            "Evaluate Province: Long An | District: Cần Giuộc | Ward:  within 0.0024123191833496094 s\n",
            "ThuanThanh H Can Giuoc => thuanthanh can giuoc\n",
            "Evaluate Province:  | District: Cần Giuộc | Ward: Thuận Thành within 0.0013501644134521484 s\n",
            "ThuanThanh Long An => thuanthanh long an\n",
            "Evaluate Province: Long An | District:  | Ward: Thuận Thành within 0.0012006759643554688 s\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "examples = [\n",
        "    \"X. Thuận Thành, H. Cần Giuộc, T. Long Aaaaan\",\n",
        "    \"Thuận Thanh, HCần Giuộc, Tlong An\",\n",
        "    \"Thuận Thành, H Cần Giuộc T. Long An\",\n",
        "    \"X ThuanThanh H. Can Giuoc, Long An\",\n",
        "    \"ThuanThanh H Can Giuoc Long An\",\n",
        "    \"X ThuanThanh H. Can Giuoc, LongAn\",\n",
        "    \"H. Can   Giuoc, Long An\",\n",
        "    \"ThuanThanh H Can Giuoc\",\n",
        "    \"ThuanThanh Long An\",\n",
        "]\n",
        "for example in examples:\n",
        "    start = time.time()\n",
        "    norm_text = normalize(example)\n",
        "    print(f\"{example} => {norm_text}\")\n",
        "    finalResult = findBestMatchAddress(norm_text)\n",
        "    end = time.time()\n",
        "    print(f\"Evaluate {finalResult} within {end - start} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84a79844-99cc-41a5-af7d-ee54c14cbfd5",
      "metadata": {
        "id": "84a79844-99cc-41a5-af7d-ee54c14cbfd5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}